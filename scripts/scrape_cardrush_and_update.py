# -*- coding: utf-8 -*-
"""
CardRush(ãƒã‚±ã‚«)ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¦æœ€æ–°è²·å–ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€
ãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥.xlsx ã® Sheet1ï¼ˆMycaå•†å“ãƒã‚¹ã‚¿å½¢å¼ï¼‰ã¨ç…§åˆã—ã¦å€¤ä»˜ã‘ã€
ãƒ»ãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥_ä¸€è‡´æŠ½å‡º.xlsx ã«ä¸€è‡´ãƒ‡ãƒ¼ã‚¿ï¼†ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
ãƒ»ãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥.xlsx ã® Sheet1 ã« 1ã€œ5è¡Œã‚’æ®‹ã—ãŸã¾ã¾ 6è¡Œç›®ã‹ã‚‰ä¸Šæ›¸ã
ãƒ»Mycaã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨CSVã‚’è‡ªå‹•å‡ºåŠ›
ã¾ã§ä¸€æ‹¬ã§è¡Œã†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
"""

import os
import sys
import re
import time
import unicodedata
import math
import tempfile
import shutil

import requests
import pandas as pd
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from pathlib import Path 

# ================== è¨­å®š ==================
# â˜… GitHubãƒªãƒã‚¸ãƒˆãƒª(climax3) åŸºæº–ã®ãƒ‘ã‚¹ã«å¤‰æ›´
REPO_ROOT = Path(__file__).resolve().parent.parent
BASE_DIR  = REPO_ROOT / "data"

# .xlsm ã«å¤‰æ›´ï¼ˆã•ã£ã data ã«å…¥ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã‚‹ï¼‰
XLSX_FILE       = BASE_DIR / "pokeca_rush.xlsm"             # å…ƒã®Mycaå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«
MATCH_OUT_FILE  = BASE_DIR / "ãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥_ä¸€è‡´æŠ½å‡º.xlsx"      # ä¸€è‡´æŠ½å‡ºï¼†ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ç”¨
MYCA_CSV_FILE   = BASE_DIR / "ãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥_Mycaã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨.csv"


SHEET1_NAME = "Sheet1"

# Sheet1 å´ã®åˆ—ä½ç½®ï¼ˆMycaãƒ†ãƒ³ãƒ—ãƒ¬ãã®ã¾ã¾ï¼‰
S1_NAME_COL_LETTER  = "C"  # åå‰ (display_name)
S1_MODEL_COL_LETTER = "F"  # å‹ç•ª (cardnumber)
S1_PRICE_COL_LETTER = "O"  # ä¾¡æ ¼ï¼ˆã“ã“ã‚’ä¸Šæ›¸ã = buy_priceï¼‰
S1_G_COL_LETTER     = "G"  # rarity (AR åˆ¤å®šç”¨)

# CardRush å´ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœ DataFrameï¼‰ã‚’
# A=åå‰ / B=å‹ç•ª / C=ä¾¡æ ¼ ã¨ã—ã¦æ‰±ã†
S2_NAME_COL_LETTER  = "A"
S2_MODEL_COL_LETTER = "B"
S2_PRICE_COL_LETTER = "C"

threshold = 0.90  # åå‰ï¼‹å‹ç•ªä¸€è‡´ç‡ã®å¹³å‡ãŒã“ã‚Œä»¥ä¸Šãªã‚‰åŒä¸€ã‚«ãƒ¼ãƒ‰ã¨ã¿ãªã™

# ====== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š ======
BASE_URL = "https://cardrush.media/pokemon/buying_prices"
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    )
}
PRICE_THRESHOLD = 90  # ã“ã®é‡‘é¡ä»¥ä¸‹ã¯é™¤å¤–

# å‹ç•ªæŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
MODEL_CANDIDATE_RE = re.compile(r"[A-Za-z0-9]+\/[A-Za-z0-9]+")
ALT_MODEL_RE = re.compile(r"[A-Za-z0-9]{1,6}[-\/][A-Za-z0-9]{1,10}(?:\/[0-9]{1,6})?")


# ================== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==================
try:
    from rapidfuzz.distance import Levenshtein

    def sim_ratio(a, b):
        if not a and not b:
            return 1.0
        if not a or not b:
            return 0.0
        return Levenshtein.normalized_similarity(a, b)

except Exception:
    from difflib import SequenceMatcher

    def sim_ratio(a, b):
        if not a and not b:
            return 1.0
        if not a or not b:
            return 0.0
        return SequenceMatcher(None, a, b).ratio()


def get_col_by_letter(df, letter: str) -> str:
    """A,B,C... ã‹ã‚‰ DataFrame ã®åˆ—åã‚’å–å¾—"""
    idx = ord(letter.upper()) - ord("A")
    if idx < 0 or idx >= len(df.columns):
        raise IndexError(f"åˆ— {letter} ãŒã‚·ãƒ¼ãƒˆã«å­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆåˆ—æ•°={len(df.columns)}ï¼‰")
    return df.columns[idx]


def normalize_key(s):
    if s is None:
        return ""
    s = unicodedata.normalize("NFKC", str(s)).lower()
    for ch in [
        "ï¼ˆ", "ï¼‰", "[", "]", "(", ")", "ã€Œ", "ã€", "ã€", "ã€", "ã€", "ã€‘",
        "â˜…", "â˜†", "ãƒ»", "/", "\\", "-", "_", "ã€€", " ", "ï¼š", ":"
    ]:
        s = s.replace(ch, "")
    return s


def frag(s, n=3):
    return s[:n] if s else ""


def try_parse_price(text: str):
    if not text:
        return None
    s = text.replace("Â¥", "").replace("å††", "").replace(",", "").strip()
    m = re.search(r"(\d+)", s)
    return int(m.group(1)) if m else None


# ================== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°éƒ¨ ==================
def detect_columns(table):
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ˜ãƒƒãƒ€ãŒã‚ã‚Œã°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¨å®šã€‚ç„¡ã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"""
    headers = []
    thead = table.find("thead")
    if thead:
        headers = [th.get_text(strip=True) for th in thead.find_all("th")]
    else:
        first_tr = table.find("tr")
        if first_tr:
            ths = first_tr.find_all("th")
            if ths:
                headers = [th.get_text(strip=True) for th in ths]

    name_idx = model_idx = price_idx = None
    for i, h in enumerate(headers):
        hl = h.lower()
        if any(k in hl for k in ("ã‚«ãƒ¼ãƒ‰", "å•†å“", "name")):
            name_idx = i
        if any(k in hl for k in ("å‹ç•ª", "å‹", "code", "model", "å“ç•ª", "ç•ªå·")):
            model_idx = i
        if any(k in hl for k in ("è²·å–", "è²·", "ä¾¡æ ¼", "å††", "price")):
            price_idx = i

    if name_idx is None:
        name_idx = 0
    if model_idx is None:
        model_idx = 3
    if price_idx is None:
        price_idx = -1
    return name_idx, model_idx, price_idx


def parse_page(html: str):
    """1ãƒšãƒ¼ã‚¸åˆ†ã®HTMLã‚’è§£æã—ã€ã‚«ãƒ¼ãƒ‰æƒ…å ±ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    soup = BeautifulSoup(html, "lxml")
    table = soup.find("table")
    if not table:
        return []

    name_idx, model_idx, price_idx = detect_columns(table)
    rows = table.find_all("tr")
    results = []

    for tr in rows:
        tds = tr.find_all(["td", "th"])
        if not tds:
            continue
        cells = [td.get_text(" ", strip=True) for td in tds]

        # ãƒ˜ãƒƒãƒ€è¡Œã£ã½ã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—
        joined = " ".join(cells)
        if ("ã‚«ãƒ¼ãƒ‰" in joined and "è²·å–" in joined) or ("å•†å“" in joined and "ä¾¡æ ¼" in joined):
            continue

        name = cells[name_idx] if name_idx < len(cells) else ""
        model = cells[model_idx] if model_idx < len(cells) else ""

        # å‹ç•ªãŒç©ºãªã‚‰ã‚»ãƒ«å…¨ä½“ã‹ã‚‰æŠ½å‡º
        if not model:
            for c in cells:
                m = MODEL_CANDIDATE_RE.search(c)
                if m:
                    model = m.group()
                    break
            if not model:
                m2 = ALT_MODEL_RE.search(" ".join(cells))
                if m2:
                    model = m2.group()

        # ä¾¡æ ¼æŠ½å‡º
        if 0 <= price_idx < len(cells):
            price = try_parse_price(cells[price_idx])
        else:
            price = try_parse_price(cells[-1] if cells else "")

        if price is None or price <= PRICE_THRESHOLD:
            continue

        results.append(
            {
                "name": name.strip(),
                "model": model.strip(),
                "price": price,
            }
        )
    return results


def fetch_page(page: int, session: requests.Session):
    """ãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
    url = BASE_URL if page == 1 else f"{BASE_URL}?page={page}"
    resp = session.get(url, headers=HEADERS, timeout=20)
    if resp.status_code != 200:
        print(f"âš ï¸ HTTP {resp.status_code}: {url}")
        return None
    return resp.text


def scrape_cardrush():
    """CardRush å…¨ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¦ DataFrame ã‚’è¿”ã™"""
    all_cards = []
    page = 1

    with requests.Session() as session:
        while True:
            print(f"ğŸ“„ Fetching page {page}...")
            html = fetch_page(page, session)
            if not html:
                print("âŒ HTTPã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ç©ºãƒšãƒ¼ã‚¸ã€‚åœæ­¢ã—ã¾ã™ã€‚")
                break

            items = parse_page(html)
            if not items:
                print("ğŸ”š ã“ã®ãƒšãƒ¼ã‚¸ã«æŠ½å‡ºé …ç›®ãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
                break

            all_cards.extend(items)
            print(f"âœ… Page {page}: {len(items)}ä»¶å–å¾—ã€‚åˆè¨ˆ {len(all_cards)}ä»¶ã€‚")

            page += 1
            time.sleep(0.3)  # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›

    if not all_cards:
        raise RuntimeError("âš ï¸ æŠ½å‡ºçµæœãŒç©ºã§ã™ã€‚")

    df = pd.DataFrame(all_cards).drop_duplicates(subset=["name", "model", "price"])
    df = df[["name", "model", "price"]]  # A:åå‰, B:å‹ç•ª, C:ä¾¡æ ¼
    return df


# ================== å€¤ä»˜ã‘ãƒ«ãƒ¼ãƒ« ==================
def adjust_price(row, s1_price_col, g_col_name):
    """
    CardRushå´ã®ä¾¡æ ¼(S2_ç…§åˆä¾¡æ ¼) ã¨ rarity(Gåˆ—)ã‹ã‚‰ã€
    æœ€çµ‚çš„ã« Sheet1 ã® Oåˆ—ã¸å…¥ã‚Œã‚‹ä¾¡æ ¼ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """

    raw = row.get("S2_ç…§åˆä¾¡æ ¼", None)
    fallback = row.get(s1_price_col, None)

    # S2å´ä¾¡æ ¼ãŒãªã„ â†’ å…ƒã®ä¾¡æ ¼ã®ã¾ã¾
    if pd.isna(raw) or raw is None or str(raw).strip() == "":
        return fallback

    s = str(raw).replace(",", "").strip()
    try:
        base = float(s)
    except ValueError:
        return fallback

    p = int(base)
    g_val = str(row.get(g_col_name, "") or "")
    new_p = p

    # --- å€‹åˆ¥ãƒãƒƒãƒ”ãƒ³ã‚° ---
    special_map = {
        100: 50, 150: 50,
        200: 100,
        300: 150,
        400: 200,
        500: 300,
        600: 400,
        700: 500,
        800: 600,
        900: 700,
        1000: 800,
    }
    if p in special_map:
        new_p = special_map[p]

    # --- 10000ä»¥ä¸Šã®åŸºæœ¬ãƒ«ãƒ¼ãƒ« ---
    elif p >= 10000:
        # ã¾ãš1.05å€
        tmp = int(p * 1.05)

        if tmp >= 40000:
            # 4ä¸‡ä»¥ä¸Šã¯ç„¡æ¡ä»¶ã§1000å˜ä½åˆ‡ã‚Šä¸Šã’
            new_p = ((tmp // 1000) + 1) * 1000
        else:
            # 10000ã€œ39999 â†’ 100ã®ä½ã§åˆ†å²
            hundred = (tmp // 100) % 10

            # 1ã€œ5 â†’ 1000å††å˜ä½ã§åˆ‡ã‚Šæ¨ã¦
            if 1 <= hundred <= 5:
                new_p = (tmp // 1000) * 1000
            # 6ã€œ9 â†’ 1000å††å˜ä½ã§åˆ‡ã‚Šä¸Šã’
            elif 6 <= hundred <= 9:
                new_p = ((tmp // 1000) + 1) * 1000
            # 0 â†’ ãã®ã¾ã¾1000å††å˜ä½
            else:
                new_p = (tmp // 1000) * 1000

    # 1001ã€œ9999 â†’ å¤‰æ›´ãªã—
    # 0ã€œ99 ã‚‚ç‰¹ã«ãƒ«ãƒ¼ãƒ«ãªã—

    # --- ã“ã“ã‹ã‚‰æœ€çµ‚ä»•ä¸Šã’ãƒ«ãƒ¼ãƒ« ---

    # 6æ¡ï¼ˆ100,000ã€œ999,999ï¼‰ã¯ 1ä¸‡ã®ä½ã§å››æ¨äº”å…¥
    if 100000 <= new_p <= 999999:
        q = new_p // 10000      # ä¸‡ã®ä½
        r = new_p % 10000       # ä¸‹4æ¡
        if r >= 5000:
            q += 1
        new_p = q * 10000

    # 7æ¡ä»¥ä¸Šï¼ˆ1,000,000ã€œï¼‰ã¯ 10ä¸‡ã®ä½ã‚’å¸¸ã«åˆ‡ã‚Šä¸Šã’
    if new_p >= 1000000:
        new_p = ((new_p + 100000 - 1) // 100000) * 100000

    # --- ARè£œæ­£ ---
    if new_p <= 299 and g_val == "AR":
        new_p = 300

    return new_p


# ================== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==================
def main():
    xlsx_path     = XLSX_FILE
    match_out_path = MATCH_OUT_FILE
    myca_csv_path  = MYCA_CSV_FILE

    if not os.path.exists(xlsx_path):
        print(f"âœ– å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {xlsx_path}")
        sys.exit(1)

    # ---- â‘  CardRush ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆSheet2ç›¸å½“ï¼‰ ----
    print("=== CardRush ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ ===")
    s2 = scrape_cardrush()
    print(f"=== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†: {len(s2)} ä»¶ ===")

    # DataFrame ã®åˆ—ã¯ [name, model, price] ãªã®ã§
    s2.columns = ["name", "model", "price"]

    # ---- â‘¡ å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã® Sheet1 ã‚’èª­ã¿è¾¼ã¿ ----
    s1 = pd.read_excel(xlsx_path, sheet_name=SHEET1_NAME, dtype=str)

    # åˆ—å–å¾—
    s1_name_col  = get_col_by_letter(s1, S1_NAME_COL_LETTER)
    s1_model_col = get_col_by_letter(s1, S1_MODEL_COL_LETTER)
    s1_price_col = get_col_by_letter(s1, S1_PRICE_COL_LETTER)
    s1_g_col     = get_col_by_letter(s1, S1_G_COL_LETTER)  # ARåˆ¤å®š

    s2_name_col  = get_col_by_letter(s2, S2_NAME_COL_LETTER)  # "name"
    s2_model_col = get_col_by_letter(s2, S2_MODEL_COL_LETTER) # "model"
    s2_price_col = get_col_by_letter(s2, S2_PRICE_COL_LETTER) # "price"

    # æ­£è¦åŒ–ã‚­ãƒ¼
    s1["_name"]  = s1[s1_name_col].fillna("").map(normalize_key)
    s1["_model"] = s1[s1_model_col].fillna("").map(normalize_key)
    s2["_name"]  = s2[s2_name_col].fillna("").map(normalize_key)
    s2["_model"] = s2[s2_model_col].fillna("").map(normalize_key)

    # ãƒã‚±ãƒƒãƒˆä½œæˆ
    s2["__k_model3"] = s2["_model"].map(lambda x: frag(x, 3))
    s2["__k_name3"]  = s2["_name"].map(lambda x: frag(x, 3))

    bucket_full, bucket_model, bucket_name = {}, {}, {}
    for idx, row in s2.iterrows():
        bucket_full.setdefault((row["__k_model3"], row["__k_name3"]), []).append(idx)
        bucket_model.setdefault(row["__k_model3"], []).append(idx)
        bucket_name.setdefault(row["__k_name3"], []).append(idx)

    # ---- â‘¢ ç…§åˆï¼ˆåŒã˜ s2 è¡Œã‚’ãªã‚‹ã¹ãå†åˆ©ç”¨ã—ãªã„ï¼‰----
    rows = []
    used_s2 = set()

    for i, r1 in s1.iterrows():
        k = (frag(r1["_model"], 3), frag(r1["_name"], 3))

        # åŸºæœ¬å€™è£œ
        base_candidates = (
            bucket_full.get(k)
            or bucket_model.get(k[0])
            or bucket_name.get(k[1])
            or list(s2.index)
        )

        # â˜…ã€Œã²ã‹ã‚‹ï½ã€å°‚ç”¨çµã‚Šè¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯
        orig_name_s1 = str(r1[s1_name_col] or "")

        if "ã²ã‹ã‚‹" in orig_name_s1:
            cand = [
                j for j in base_candidates
                if "ã²ã‹ã‚‹" in str(s2.at[j, s2_name_col] or "")
            ]

            if "æ—§" in orig_name_s1:
                cand_kyu = [
                    j for j in cand
                    if "æ—§" in str(s2.at[j, s2_name_col] or "")
                ]
                if cand_kyu:
                    cand = cand_kyu

            candidates = cand if cand else base_candidates
        else:
            candidates = base_candidates

        best_j, best_score, best_nr, best_mr = None, -1, 0, 0
        best_unused_j, best_unused_score = None, -1
        best_unused_nr, best_unused_mr = 0, 0

        n1, m1 = r1["_name"], r1["_model"]

        for j in candidates:
            n2, m2 = s2.at[j, "_name"], s2.at[j, "_model"]
            nr, mr = sim_ratio(n1, n2), sim_ratio(m1, m2)
            sc = (nr + mr) / 2

            # å…¨ä½“ã®ãƒ™ã‚¹ãƒˆ
            if sc > best_score:
                best_score = sc
                best_j = j
                best_nr, best_mr = nr, mr

            # æœªä½¿ç”¨ã®ä¸­ã§ã®ãƒ™ã‚¹ãƒˆ
            if j not in used_s2 and sc > best_unused_score:
                best_unused_score = sc
                best_unused_j = j
                best_unused_nr, best_unused_mr = nr, mr

            if sc >= 0.999:
                # ã»ã¼å®Œå…¨ä¸€è‡´ãªã‚‰ãã‚Œä»¥ä¸Šè¦‹ãªã„
                continue

        # æœªä½¿ç”¨ã§é–¾å€¤ä»¥ä¸Šã®å€™è£œãŒã‚ã‚Œã°ãã£ã¡å„ªå…ˆ
        if best_unused_j is not None and best_unused_score >= threshold:
            chosen_j = best_unused_j
            chosen_score = best_unused_score
            chosen_nr, chosen_mr = best_unused_nr, best_unused_mr
        else:
            chosen_j = best_j
            chosen_score = best_score
            chosen_nr, chosen_mr = best_nr, best_mr

        if chosen_j is not None:
            used_s2.add(chosen_j)

        rows.append({
            "s1_idx": i,
            "s2_idx": chosen_j,
            "åå‰ä¸€è‡´ç‡": chosen_nr,
            "å‹ç•ªä¸€è‡´ç‡": chosen_mr,
            "å¹³å‡ä¸€è‡´ç‡": chosen_score,
            "é–¾å€¤ä»¥ä¸Š": chosen_score >= threshold
        })

    match_df = pd.DataFrame(rows)

    # ---- â‘£ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ ----
    s1_key = s1[[s1_name_col, s1_model_col, s1_price_col]].copy()
    s1_key.columns = ["S1_åå‰", "S1_å‹ç•ª", "S1_ä¾¡æ ¼"]
    s1_key["s1_idx"] = s1.index

    s2_key = s2[[s2_name_col, s2_model_col, s2_price_col]].copy()
    s2_key.columns = ["S2_åå‰", "S2_å‹ç•ª", "S2_ä¾¡æ ¼"]
    s2_key["s2_idx"] = s2.index

    report = (
        match_df
        .merge(s1_key, on="s1_idx", how="left")
        .merge(s2_key, on="s2_idx", how="left")
        [["S1_åå‰","S1_å‹ç•ª","S1_ä¾¡æ ¼",
          "S2_åå‰","S2_å‹ç•ª","S2_ä¾¡æ ¼",
          "åå‰ä¸€è‡´ç‡","å‹ç•ªä¸€è‡´ç‡","å¹³å‡ä¸€è‡´ç‡","é–¾å€¤ä»¥ä¸Š"]]
    )

    # ---- â‘¤ ä¸€è‡´ã—ãŸè¡Œã ã‘æŠ½å‡º ----
    keep_idx = match_df.loc[match_df["é–¾å€¤ä»¥ä¸Š"], "s1_idx"]
    if len(keep_idx) == 0:
        print("âš  ä¸€è‡´ã—ãŸè¡ŒãŒ1ä»¶ã‚‚ã‚ã‚Šã¾ã›ã‚“ï¼ˆthreshold ã‚’ä¸‹ã’ã‚‹ã¨ãƒãƒƒãƒã™ã‚‹ã‹ã‚‚ï¼‰")
        sys.exit(0)

    s1_filtered = s1.loc[keep_idx].copy().reset_index(drop=True)
    s1_filtered["s1_idx"] = keep_idx.values

    # s2å´æƒ…å ±ã‚’çµåˆ
    s2_info = (
        match_df.loc[match_df["é–¾å€¤ä»¥ä¸Š"], ["s1_idx","s2_idx","å¹³å‡ä¸€è‡´ç‡"]]
        .merge(s2_key, on="s2_idx", how="left")
        .rename(columns={
            "S2_ä¾¡æ ¼": "S2_ç…§åˆä¾¡æ ¼",
            "S2_åå‰": "S2_ç…§åˆåå‰",
            "S2_å‹ç•ª": "S2_ç…§åˆå‹ç•ª"
        })
    )

    s1_filtered = s1_filtered.merge(
        s2_info[["s1_idx","S2_ç…§åˆä¾¡æ ¼","S2_ç…§åˆåå‰","S2_ç…§åˆå‹ç•ª","å¹³å‡ä¸€è‡´ç‡"]],
        on="s1_idx",
        how="left"
    )

    # ---- â‘¥ ä¾¡æ ¼å¤‰æ› ----
    s1_filtered["__new_price"] = s1_filtered.apply(
        lambda r: adjust_price(r, s1_price_col, s1_g_col),
        axis=1
    )

    # Oåˆ—ã¸ä¸Šæ›¸ãï¼ˆDataFrameä¸Šï¼‰
    s1_filtered[s1_price_col] = s1_filtered["__new_price"]
    s1_filtered.drop(columns=["__new_price"], inplace=True)

    # ---- â‘¦ ä¸€è‡´æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç¢ºèªç”¨ï¼‰ã‚’ä¿å­˜ ----
    match_out_full = match_out_path
    with pd.ExcelWriter(match_out_full, engine="openpyxl") as writer:
        s1_filtered.to_excel(writer, sheet_name="Sheet1_ä¸€è‡´æŠ½å‡º", index=False)
        report.to_excel(writer, sheet_name="ç…§åˆãƒ¬ãƒãƒ¼ãƒˆ", index=False)
    print(f"âœ“ ä¸€è‡´æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›: {match_out_full}")

    # === ã“ã“ã‹ã‚‰ã€ã€Œãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥.xlsx ã® Sheet1 ã« 6è¡Œç›®ã‹ã‚‰ä¸Šæ›¸ãã€ ===

    # å…ƒã®Sheet1ã®åˆ—æ§‹æˆã‚’å–å¾—ï¼ˆs1_filteredã«ã¯ä½™è¨ˆãªåˆ—ã‚‚å…¥ã£ã¦ã‚‹ã®ã§ï¼‰
    original_columns = s1.columns  # å…ƒSheet1ã®åˆ—é †
    export_df = s1_filtered[original_columns].copy()

    # ---- â‘§ Excelãƒ–ãƒƒã‚¯ã‚’é–‹ã„ã¦ Sheet1 ã‚’æ›´æ–° ----
    wb = load_workbook(xlsx_path, keep_vba=True)  # ã“ã“ã‚’å¤‰æ›´
    ws = wb[SHEET1_NAME]


    # 1ã€œ5è¡Œç›®ã¯ãã®ã¾ã¾æ®‹ã—ã€6è¡Œç›®ã‹ã‚‰ export_df ã‚’æ›¸ãè¾¼ã‚€
    start_row = 6
    n_rows, n_cols = export_df.shape

    # ã¾ãšã€æ—¢å­˜ã® 6è¡Œç›®ä»¥é™ã‚’å…¨éƒ¨ã‚¯ãƒªã‚¢ã—ã¦ãŠãï¼ˆè¦‹ãŸç›®ã‚’ç¶ºéº—ã«ã™ã‚‹ãŸã‚ï¼‰
    max_row = ws.max_row
    max_col = ws.max_column
    for r in range(start_row, max_row + 1):
        for c in range(1, max_col + 1):
            ws.cell(row=r, column=c).value = None

    # 6è¡Œç›®ã‹ã‚‰æ›¸ãè¾¼ã¿ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¯ä¸è¦ãªã®ã§ã€DataFrameã®å†…å®¹ã ã‘ï¼‰
    for i in range(n_rows):
        row_idx = start_row + i
        for j in range(n_cols):
            value = export_df.iat[i, j]
            ws.cell(row=row_idx, column=j + 1).value = value

    wb.save(xlsx_path)
    print(f"âœ“ ãƒã‚±ã‚«ãƒ©ãƒƒã‚·ãƒ¥.xlsx ã® Sheet1 ã‚’ 6è¡Œç›®ã‹ã‚‰ä¸Šæ›¸ãã—ã¾ã—ãŸ: {xlsx_path}")

    # ---- â‘¨ Mycaç”¨CSVè‡ªå‹•å‡ºåŠ› ----
    # ä¸Šæ›¸ãå¾Œã® Sheet1 ã‚’ãã®ã¾ã¾CSVåŒ–ï¼ˆ1ã€œ5è¡Œç›®ã‚‚å«ã‚ã¦ï¼‰
    df_for_csv = pd.read_excel(xlsx_path, sheet_name=SHEET1_NAME, header=None, dtype=object)
    df_for_csv.to_csv(myca_csv_path, index=False, header=False, encoding="utf-8-sig")

    print(f"âœ“ Mycaã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨CSVã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {myca_csv_path}")
    print("=== å…¨å‡¦ç†å®Œäº† ===")


if __name__ == "__main__":
    main()
